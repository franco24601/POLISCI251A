---
title: "Interactive Code Lecture 6 (week 4)"
author: "POLISCI 251A"
date: "July 14, 2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
### Let's start with an clean environment
rm(list=ls())
```


## 1. Setting up Iraq War Vote dataset

### 1.1

Again, we're going to analyze the Senate's vote on the Iraq war authorization. We'll find this data set in the PSCL package, which is called `pscl` in R.

To get started, we need to install and load the library. Last class we installed the 'pscl' package so you don't have to do it again. 


```{r}
### Clean your environment
rm(list=ls())
### Load the pscl library
library(pscl)
```


To load the data set, execute the following code.

```{r}
## Uncomment this
data(iraqVote)
```

**Note: The dataset might appear as "Promise" until you do something with it**

## 2. Prediction using linear models

### 2.1 

Let's fit a predictive model using a linear probability model. Using a linear regression, regress the vote against rep and gorevote.

- `y` is the dependent variable here.
- `rep` is the independent variable.
- `gorevote` is the vote for Al Gore in the senator's state

```{r}
## YOUR CODE HERE
reg_lm <- lm(y ~ rep + gorevote, data = iraqVote)
summary(reg_lm )
```

### 2.2

Calculate and summarize the predicted probabilities. What do you notice about the predicted probabilities? (in particular, the maximum and minimum values)

```{r}
## YOUR CODE HERE
pred_prob_lm <- predict(reg_lm )
summary(pred_prob_lm)
```

### 2.3

Write a function that takes the predicted probabilities and a threshold as arguments, this  function should return a classification decision (0 or 1). Use that function to classify each senator as Yay or Nay on the Iraq vote.

**Hint: Use the function 'ifelse()' to create your vector of classifications**

```{r}
#############
## Classification function
## Syntax:
## clas_funct(prob, threshold)
## prob: a vector of predicted probabilities
## threshold: a numeric threshold betweeen 0 and 1 (inclusive)
## The function should return a vector of classifications
############
class_func <- function(prob, threshold){
  class <- ifelse(prob>=threshold, 1, 0)
  return(class)
}

```

Using your function, your vector 'pred_prob_lm', and a threshold of 0.5 calculate the classifications for your model. Store your classfications in an object called 'class_lm'

```{r}
# estimate your classification, 
class_lm <- class_func(pred_prob_lm, 0.5)
# take a peek using the function 'head()'
head(class_lm)
```


### 2.4

What proportion of senators do you classify as a likely Iraq Vote? What proportion of Democrats and Republicans?

```{r}
# proportion of all senators
mean(class_lm)

# proportion of dems
sum(class_lm[iraqVote$rep==0]) / sum(iraqVote$rep==0)

# proportion of rep
sum(class_lm[iraqVote$rep==1]) / sum(iraqVote$rep==1)
```


## 2.5 Challenge (Only if you have taken matrix algebra)

Using the linear regression, calculate predicted probabilities for each of the observations by creating an appropriate matrix of predictors and then multiplyng this matrix by the coefficients. 

*Hint: Use the inner product to multiply the matrix*

```{r}
# create matrix of predictors using the function cbind()
# Do not forget to include a cloumn of ones. 
indep.matrix <- cbind(1, iraqVote$rep, iraqVote$gorevote)

# multiply by coefficients using %*%
pred_prob_lm2<- c(indep.matrix%*%reg_lm$coef) 

# Compare your results with the ones obtained before in 'pred_prob_lm'. They should be the same
head(pred_prob_lm2)
head(pred_prob_lm)
```


## 3. Fitting a Logistic Regression ###

A logistic regression can be defined as a generalization of a linear regression. That's why we call it Generalized Linear Model.

### 3.1

Fit a logistic regression of `y` on `rep` and `gorevote`. Store it in an object called `re_glm`.
We specify `family = binomial` to let glm know that we're interested in a logistic regression. And just like `lm`, data is how we specify the data we'll use.

```{r}
# Run yout glm model
reg_glm <- glm(y~rep + gorevote, family = binomial,data = iraqVote)
```

### 3.2


Retrive the predicted probabilities from the model above and store it in an object `pred_prob_glm`.
```{r}
# predict
pred_prob_glm <- reg_glm$fitted.values
```

### 3.3

Compare the predicted probabilities from the linear model and the logistic regression. How do the predicted probabilities of the two functions differ?
```{r}
plot(pred_prob_lm ~ c(pred_prob_glm), xlab = 'Logistic predictions', ylab = 'Linear predictions')
abline(h =1)
abline(v = 1)
```

### 3.4

Now, using the probabilities and the classification function and threshold from 2.3, classify the senators using the logistic regression function.
```{r}
class_glm<- class_func(pred_prob_glm , 0.5)
## teake a peek using head()
head(class_glm)
```

### 3.5

Using `table()`, compare the classification from the linear model and the logistic regression. What do you notice?
```{r}
table(class_lm, class_glm)
```


### 3.6

Again, using `table()`, create a confusion matrix for each model

```{r}
## matrix lm
table(iraqVote$y, class_lm)
# matrix glm
table(iraqVote$y, class_glm)
```


### 4. Model Evaluation 

### 4.1 

We are now ready to begin evaluating our model. Write three functions to calculate

- Accuracy is the ratio of correct predictions (both positive and negative) to all predictions. The formula for accuracy is:
$$Accuracy=\dfrac{TP + TN}{TP+TN+FP+FN}$$

- Precision measures the accuracy of the classifier when it predicts an example to be positive. The formula for precision is:
$$Precision=\dfrac{TP}{TP+FP}$$

- Recall measures the ability of the classifier to find positive examples. The formula for recall is:
$$Recall=\dfrac{TP}{TP+FN}$$

- F-score is the harmonic mean of precision and recall. The formula for F-score is:
$$F=\dfrac{2*Precision*Recall}{Precision+Recall}$$

```{r,echo=F}
### The following functions take a vector of predicted and a vector of observed values and calculate:
### Accuracy : tp + tn / all observations
### Precision: tp / (tp + fp)
### Recall: tp / (tp+fn)

### Accuracy
accuracy <- function(predicted, true){
  score <- (sum(predicted & true) + sum(!predicted & !true)) / length(true)
  return(score)
}

### Precision 
precision <- function(predicted, true){
  score <- sum(predicted & true) / sum(predicted)
  return(score)
}

## Recall
recall <- function(predicted, true){
  recall = sum(predicted & true) / sum(true)
  return(recall)
}
```

### 4.2

Using the functions compare the accuracy, precision and recall of the LM classifications and the logistic regression predictions. On the basis of these scores, can you make a strong argument for selecting either model?  
```{r}
cat('Linear Regression', '\n')
cat('Accuracy', '\n'); accuracy(class_lm, iraqVote$y)
cat('Precision', '\n'); precision(class_lm, iraqVote$y)
cat('Recall', '\n'); recall(class_lm, iraqVote$y)

cat('Logistic Regression', '\n')
cat('Accuracy', '\n'); accuracy(class_glm, iraqVote$y)
cat('Precision', '\n'); precision(class_glm, iraqVote$y)
cat('Recall', '\n'); recall(class_glm, iraqVote$y)
```



*Complete the following sections at home*


### 5. Challenge

Finally, what happens as we vary the threshold on our classification? Let's focus on the predictions from the logistic regression only. Using a for loop, assess how the precision and recall varies as the threshold moves from 0 to 1.

```{r}
# create a vector of different threshold possibilities
thresh <- seq(0.0, 1, len = 1000)

# loop through and calculate classes based on these probabilities
store_f <- store_prec <- store_rec <- c()
for(z in 1:length(thresh)){
  temp_class<- class_func(pred_prob_glm, thresh[z])
  store_prec[z]<- precision(temp_class, iraqVote$y)
  store_rec[z]<- recall(temp_class, iraqVote$y)
  store_f[z]<- store_prec[z]*store_rec[z]/(store_prec[z] + store_rec[z])
}
```

### 5.1 

What is the threshold that maximizes f? What do you notice as we trade off precision and recall?

```{r}
thresh[which.max(store_f)]
plot(store_prec ~ store_rec)
```



## 6. Exploring Logit functions 

### 6.1

The natural logarithm function in R is `log`. If unfamiliar, try applying log to a few numbers. For example what does the following yield?

```{r}
log(exp(5)) 
```

### 6.2 

Write a function for the logit function:

$$x=log(\dfrac{p}{1-p})$$

```{r}
## Your function
logit_func<- function(p){
  out<- log(p/( 1- p))
  return(out)
}
```

### 6.3 

Using your function, plot the logit function from 0 to 1.  Where does the logit function equal 0?  

```{r}
# get a sequence of poitns
p <- seq(0,1,len=1000)

# plot those points and logit
plot(logit_func(p) ~ p, xlab = 'Probability', ylab = 'Logit(p)', type='l' , lwd = 3)

# add lines
abline(h = 0)
abline(v = 0.5)
```

### 6.4 

Now write a function for the inverse logit function:

$$p=\dfrac{1}{1+exp^{-x}}$$

```{r}
# inverse logit
logit_inv_func<- function(a){
  out <- 1/(1 + exp(-a))
  return(out)
}
```

Plot the logit function over the range -4 to 4. What do you notice is true about the rate of the change of the function at 0? What about the rate of change at -4 and 4? 

```{r}
# plot
a_seq <- seq(-4, 4, len = 1000)
linv_out <- logit_inv_func(a_seq)

plot(linv_out~a_seq, type='l', xlab='a', ylab = 'logistic(a)', main = "Logistic function")
abline(v = 0)
abline(h = 0.5)
```

